{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data.load_dataset import load_dataset\n",
    "from data.merge_dataset import merge_dataset\n",
    "from data.feature_engineering import apply_log_transformation, ClusteringModel\n",
    "# from model.inference import save_csv\n",
    "# from model.feature_select import select_features\n",
    "# from model.data_split import split_features_and_target\n",
    "# from model.model_train import cv_train, set_model, optuna_train\n",
    "import argparse\n",
    "import os\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터 불러오기\n",
    "train_data, test_data, sample_submission, interest_data, subway_data, school_data, park_data = load_dataset()\n",
    "\n",
    "# 기존 데이터에 새로운 feature들을 병합한 데이터프레임 불러오기\n",
    "train_data, test_data = merge_dataset(train_data, test_data, interest_data, subway_data, school_data, park_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 중복도 낮은 행 삭제\n",
    "groups = train_data.groupby([\"latitude\", \"longitude\"])[\"index\"].count()\n",
    "conditioned_groups_index = groups[(groups >= 2) & (groups <= 5)].index # 이 범위를 파라미터로 조정하는걸로\n",
    "small_groups = train_data[\n",
    "    train_data[\"latitude\"].isin(conditioned_groups_index.get_level_values(0)) &\n",
    "    train_data[\"longitude\"].isin(conditioned_groups_index.get_level_values(1))\n",
    "]\n",
    "train_data.drop(small_groups.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built_year > 2024 행 삭제\n",
    "train_data = train_data[train_data[\"built_year\"] < 2024]\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log 변환\n",
    "train_data, test_data = apply_log_transformation(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가격 Clustering EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 데이터 정렬 및 인덱스 리셋\n",
    "sorted_train_data = train_data.sort_values(by=\"log_deposit\").reset_index(drop=True)\n",
    "# deposit을 기준으로 그룹을 나눔\n",
    "# 10,000 미만은 그룹 0, 10,000~100,000 사이는 그룹 1, 100,000 이상은 100,000 단위로 그룹화\n",
    "def categorize_deposit(deposit):\n",
    "    if deposit < 9.5:\n",
    "        return 0\n",
    "    elif deposit <= 10.5:\n",
    "        return 1\n",
    "    elif deposit <= 11:\n",
    "        return 2\n",
    "    elif deposit <= 11.5:\n",
    "        return 3\n",
    "    elif deposit <= 12:\n",
    "        return 4\n",
    "    elif deposit <= 12.5:\n",
    "        return 5\n",
    "    elif deposit <= 13:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7 \n",
    "# 그룹화 적용\n",
    "sorted_train_data[\"deposit_group\"] = sorted_train_data[\"log_deposit\"].apply(categorize_deposit)\n",
    "# 그룹별 통계 출력\n",
    "train_data = sorted_train_data\n",
    "print(train_data.groupby(\"deposit_group\")[\"log_deposit\"].agg([\"min\", \"max\", \"mean\", \"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Select\n",
    "selected_cols = [\n",
    "    \"log_area_m2\",\n",
    "    \"built_year\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"log_subway_distance\",\n",
    "    \"contract_year_month\",\n",
    "    \"num_of_subways_within_radius\",\n",
    "    \"park_exists\",\n",
    "    \"region\",\n",
    "    \"region_mean\",\n",
    "]\n",
    "X, test_data = train_data[selected_cols], test_data[selected_cols]\n",
    "\n",
    "# Data Split\n",
    "y = train_data[\"deposit_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X: {X.columns}\")\n",
    "print(f\"test_data: {test_data.columns}\")\n",
    "print(f\"y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = str(input(\"run 이름을 입력하세요 :\"))\n",
    "selected_model = str(input(\"model 명을 입력하세요 (xgb/rf) :\"))\n",
    "opt = bool(input(\"Optuna 사용 여부를 입력하세요 (뭐라도 입력 시 사용) :\"))\n",
    "\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"thread\"),\n",
    "    dir=None,  # 로컬에 로그 저장하지 않음\n",
    "    entity=\"remember-us\", # team name,\n",
    "    project=\"deposit\", # project name\n",
    "    name=run, # run name\n",
    "    config={\n",
    "        \"User\": os.path.basename(os.path.dirname(os.getcwd())) # jupyter는 이렇게\n",
    "    } # common setting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, X, y, params):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    match model_name:\n",
    "        case \"xgb-cls\":\n",
    "            model = xgb.XGBClassifier(**params, random_state=42, device=\"cuda\", use_label_encoder=False, n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_valid)\n",
    "            score = log_loss(y_valid, y_pred_proba)\n",
    "            \n",
    "        case \"xgb-reg\":\n",
    "            model = xgb.XGBRegressor(**params, random_state=42, device=\"cuda\", n_jobs=-1)\n",
    "            model.fit(X_train, y_train[\"log_deposit\"])\n",
    "\n",
    "            y_pred = model.predict(X_valid)\n",
    "            score = mean_absolute_error(y_valid[\"deposit\"], np.expm1(y_pred))\n",
    "        \n",
    "        case \"rf-cls\":\n",
    "            model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_valid)\n",
    "            score = log_loss(y_valid, y_pred_proba)\n",
    "        \n",
    "        case \"rf-reg\":\n",
    "            model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train, y_train[\"log_deposit\"])\n",
    "\n",
    "            y_pred = model.predict(X_valid)\n",
    "            score = mean_absolute_error(y_valid[\"deposit\"], np.expm1(y_pred))\n",
    "            \n",
    "        case _:\n",
    "            raise ValueError(f\"지원하지 않는 모델 이름: {model_name}\")\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_train(model_name, X, y):\n",
    "    match model_name:\n",
    "        case \"xgb-cls\":\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "                    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                    \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "                }\n",
    "\n",
    "                return train(model_name, X, y, params)\n",
    "\n",
    "        case \"xgb-reg\":\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "                    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                    \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "                }\n",
    "                \n",
    "                return train(model_name, X, y, params)\n",
    "         \n",
    "        case \"rf-cls\":\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 1, 30),  # 깊이를 1에서 30으로 조정\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),  # 최소 샘플 분할 수\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),  # 최소 리프 샘플 수\n",
    "                }\n",
    "\n",
    "                return train(model_name, X, y, params)\n",
    "        \n",
    "        case \"rf-reg\":\n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 1, 30),  # 깊이를 1에서 30으로 조정\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),  # 최소 샘플 분할 수\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),  # 최소 리프 샘플 수\n",
    "                }\n",
    "\n",
    "                return train(model_name, X, y, params)\n",
    "\n",
    "        case _:\n",
    "            raise ValueError(f\"지원하지 않는 모델 이름: {model_name}\")\n",
    "    \n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    return study.best_params, study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deposit_group 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "match selected_model:\n",
    "    case \"xgb\": model_name = \"xgb-cls\"\n",
    "    case \"rf\": model_name = \"rf-cls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt:\n",
    "    best_params, _ = optuna_train(model_name, X, y) # 26m\n",
    "else:\n",
    "    best_params = {\n",
    "        \"n_estimators\": 252,\n",
    "        \"learning_rate\": 0.07771055959576277,\n",
    "        \"max_depth\": 11,\n",
    "        \"subsample\": 0.7986613347562391,\n",
    "        \"colsample_bytree\": 0.8422383683572395,\n",
    "        \"gamma\": 0.34407558339867306\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match selected_model:\n",
    "    case \"xgb\":\n",
    "        best_model = xgb.XGBClassifier(**best_params, random_state=42, device=\"cuda\", use_label_encoder=False, n_jobs=-1)\n",
    "    case \"rf\":\n",
    "        best_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_groups = best_model.predict(test_data)\n",
    "test_data[\"predicted_group\"] = predicted_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deposit 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "match selected_model:\n",
    "    case \"xgb\": model_name = \"xgb-reg\"\n",
    "    case \"rf\": model_name = \"rf-reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg\n",
    "group_params = {\n",
    "    0: {\"n_estimators\": 269,\n",
    "    \"learning_rate\": 0.0594699816408674,\n",
    "    \"max_depth\": 11,\n",
    "    \"subsample\": 0.7547912219027157,\n",
    "    \"colsample_bytree\": 0.7020843771180812,\n",
    "    \"gamma\": 3.037806599477243},\n",
    "    1: {\"n_estimators\": 276,\n",
    "    \"learning_rate\": 0.15579191199373718,\n",
    "    \"max_depth\": 12,\n",
    "    \"subsample\": 0.909150931054429,\n",
    "    \"colsample_bytree\": 0.8709809907337003,\n",
    "    \"gamma\": 3.936332525239126},\n",
    "    2: {\"n_estimators\": 187,\n",
    "    \"learning_rate\": 0.04512234654985014,\n",
    "    \"max_depth\": 12,\n",
    "    \"subsample\": 0.8875664116805573,\n",
    "    \"colsample_bytree\": 0.9697494707820946,\n",
    "    \"gamma\": 4.474136752138244},\n",
    "    3: {\"n_estimators\": 279,\n",
    "    \"learning_rate\": 0.11548075621633985,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.6857659688575958,\n",
    "    \"colsample_bytree\": 0.86707596884712,\n",
    "    \"gamma\": 0.2970741820173067},\n",
    "    4: {\"n_estimators\": 262,\n",
    "    \"learning_rate\": 0.10181884312738954,\n",
    "    \"max_depth\": 12,\n",
    "    \"subsample\": 0.9636784876731649,\n",
    "    \"colsample_bytree\": 0.9301563662590965,\n",
    "    \"gamma\": 3.9023500438592036},\n",
    "    5: {\"n_estimators\": 144,\n",
    "    \"learning_rate\": 0.19063571821788408,\n",
    "    \"max_depth\": 10,\n",
    "    \"subsample\": 0.7993292420985183,\n",
    "    \"colsample_bytree\": 0.5780093202212182,\n",
    "    \"gamma\": 0.7799726016810132},\n",
    "    6: {\"n_estimators\": 98,\n",
    "    \"learning_rate\": 0.13418531015780658,\n",
    "    \"max_depth\": 7,\n",
    "    \"subsample\": 0.8210566991625188,\n",
    "    \"colsample_bytree\": 0.91306660229789,\n",
    "    \"gamma\": 1.1997602717553963},\n",
    "    7: {\"n_estimators\": 237,\n",
    "    \"learning_rate\": 0.1903026381932035,\n",
    "    \"max_depth\": 8,\n",
    "    \"subsample\": 0.6737126835787389,\n",
    "    \"colsample_bytree\": 0.7374821279913889,\n",
    "    \"gamma\": 1.1574290155684595}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "deposit_group_unique = train_data[\"deposit_group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressors_per_group(train_data):\n",
    "    group_models = {}\n",
    "    group_params = {}\n",
    "    group_scores = {}\n",
    "    group_lens = {}\n",
    "    for group in tqdm(deposit_group_unique, desc=\"Training models per group\"):\n",
    "        group_data = train_data[train_data[\"deposit_group\"] == group]\n",
    "\n",
    "        X_group = group_data[selected_cols]\n",
    "        y_group = group_data[\"deposit\", \"log_deposit\"]\n",
    "\n",
    "        # 모델 훈련\n",
    "        if opt:\n",
    "            best_params, best_value = optuna_train(model_name, X_group, y_group) # 26m\n",
    "            group_params[group] = best_params\n",
    "            group_scores[group] = best_value\n",
    "        else:\n",
    "            best_params = group_params.get(group, {})\n",
    "            score = train(model_name, X_group, y_group, best_params)\n",
    "            group_scores[group] = score\n",
    "        \n",
    "        match selected_model:\n",
    "            case \"xgb\": model = xgb.XGBRegressor(**best_params, random_state=42, device=\"cuda\", n_jobs=-1)\n",
    "            case \"rf\": model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_group, y_group)\n",
    "        \n",
    "        # 각 그룹에 해당하는 모델 저장\n",
    "        group_models[group] = model\n",
    "        group_lens[group] = len(y_group)\n",
    "        \n",
    "    return group_models, group_params, group_scores, group_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. `deposit_group` 별로 회귀 모델 훈련\n",
    "group_models, group_params, group_scores, group_lens = train_regressors_per_group(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sum(score * group_lens[group] for group, score in group_scores.items())\n",
    "total_count = sum(group_lens.values())\n",
    "mean_score = scores / total_count\n",
    "\n",
    "print(f\"Mean MAE: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_per_group(test_data, group_models):\n",
    "    # 예측값을 저장할 배열 초기화\n",
    "    y_pred = np.zeros(len(test_data))\n",
    "    \n",
    "    # 그룹별로 데이터 분리 후 예측\n",
    "    for group, model in group_models.items():\n",
    "        group_data = test_data[test_data[\"predicted_group\"] == group]\n",
    "        X_group = group_data[selected_cols]\n",
    "        \n",
    "        # 각 그룹에 대해 예측\n",
    "        if len(X_group) > 0:  # 해당 그룹에 데이터가 있는 경우만 예측\n",
    "            y_pred_group = model.predict(X_group)\n",
    "            y_pred[test_data[\"predicted_group\"] == group] = y_pred_group\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = predict_per_group(test_data, group_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_params = {int(k): v for k, v in group_params.items()}\n",
    "wandb.log({\n",
    "    \"features\": selected_cols,\n",
    "    \"model\": selected_model,\n",
    "    \"params\": best_params,\n",
    "    \"group_params\": group_params,\n",
    "    # \"Valid logloss\": valid_logloss,\n",
    "    \"Valid MAE\": mean_score,\n",
    "    \"Optuna\": opt\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"deposit\"] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
