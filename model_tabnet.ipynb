{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.load_dataset import load_dataset\n",
    "from data.merge_dataset import merge_dataset\n",
    "from data.data_preprocessing import *\n",
    "from data.feature_engineering import *\n",
    "from model.data_split import split_features_and_target\n",
    "from model.inference import save_csv\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터 불러오기\n",
    "train_data, test_data, sample_submission, interest_data, subway_data, school_data, park_data = load_dataset()\n",
    "# 기존 데이터에 새로운 feature들을 병합한 데이터프레임 불러오기\n",
    "train_data, test_data = merge_dataset(train_data, test_data, interest_data, subway_data, school_data, park_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 중복도 낮은 행 삭제\n",
    "train_data: pd.DataFrame = delete_low_density(train_data, 2, 6)\n",
    "\n",
    "# built_year가 2024인 행 삭제\n",
    "train_data: pd.DataFrame = train_data[train_data[\"built_year\"] < 2024]\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# test_data에 결측치 평균으로 대체\n",
    "mv = MissingValueImputer()\n",
    "test_data[\"interest_rate\"] = mv.mean_imputer(test_data[\"interest_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation\n",
    "\n",
    "- `deposit`\n",
    "- `area_m2`\n",
    "- `nearest_subway_distance`\n",
    "- `nearest_school_distance`\n",
    "- `nearest_park_distance`\n",
    "- `nearest_leader_distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = apply_log_transformation(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data split\n",
    "X, y = split_features_and_target(train_data)\n",
    "\n",
    "# 1. 원래 데이터 쓰는 사람용 (불필요한 변수 drop: 로그변환한 변수)\n",
    "X.drop(columns=[\"index\", \"log_area_m2\", \"log_subway_distance\", \"log_school_distance\", \"log_park_distance\", \"log_leader_distance\"], inplace=True)\n",
    "y.drop(columns=\"log_deposit\", inplace=True)\n",
    "\n",
    "# 2. 로그변환한 데이터 쓰는 사람용 (불필요한 변수 drop: 로그변환하기 전 변수)\n",
    "# X.drop(columns=[\"index\", \"area_m2\", \"nearest_subway_distance\", \"nearest_school_distance\", \"nearest_park_distance\", \"nearest_leader_distance\"], inplace=True)\n",
    "# y.drop(columns=\"deposit\", inplace=True)\n",
    "\n",
    "# 3. 다빈, 성택이 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 X)\n",
    "# selected_cols = [\n",
    "#    \"log_area_m2\", \"built_year\", \"latitude\", \"longitude\", \"log_subway_distance\", \"contract_year_month\", \"num_of_subways_within_radius\", \"park_exists\", \"region\", \"region_mean\",\n",
    "# ]\n",
    "# X = X[selected_cols]\n",
    "# y.drop(columns=\"log_deposit\", inplace=True)\n",
    "\n",
    "# 4. 영균이 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 O)\n",
    "# selected_cols = [\n",
    "#    \"log_area_m2\", \"built_year\", \"latitude\", \"longitude\", \"log_leader_distance\", \"log_subway_distance\", \"log_park_distance\", \"contract_year_month\", \"num_of_subways_within_radius\", \"park_exists\", \"region\"\n",
    "# ]\n",
    "# X = X[selected_cols]\n",
    "# y.drop(columns=\"deposit\", inplace=True)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train = X_train.values\n",
    "X_valid = X_valid.values\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X: pd.DataFrame, y: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    모델을 학습하고 검증 MAE를 계산하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        model: 수행하려는 모델\n",
    "        X (pd.DataFrame): 독립 변수\n",
    "        y (pd.DataFrame): 예측 변수. deposit과 log_deposit 열로 나뉨.\n",
    "\n",
    "    Returns:\n",
    "        float: 검증 MAE\n",
    "    \"\"\"\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    X_train = X_train.values\n",
    "    X_valid = X_valid.values\n",
    "    y_train = y_train.values\n",
    "    y_valid = y_valid.values\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train),(X_valid, y_valid)], \n",
    "        eval_name=[\"train\", \"valid\"],\n",
    "        eval_metric=[\"mae\"],\n",
    "        loss_fn=torch.nn.L1Loss(),\n",
    "        max_epochs=30, \n",
    "        patience=10,\n",
    "        batch_size=2048,\n",
    "        drop_last=False,\n",
    "        warm_start=True  # warm start 활성화\n",
    "    )\n",
    "    print(\"모델 학습이 완료됐습니다. ⏲\")\n",
    "\n",
    "    # 2. 로그변환한 데이터 쓰는 사람용\n",
    "    # y_train = np.expm1(y_train) # -> 로그변환 변수 사용시 활성화\n",
    "    # y_valid = np.expm1(y_valid) # -> 로그변환 변수 사용시 활성화\n",
    "\n",
    "    # 예측 및 로그 변환 복구\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # y_train_pred = np.expm1(y_train_pred) # 2. 로그변환한 데이터 쓰는 사람용 -> log_deposit의 inverse log 처리\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    # y_valid_pred = np.expm1(y_valid_pred) # 2. 로그변환한 데이터 쓰는 사람용 -> log_deposit의 inverse log 처리\n",
    "\n",
    "    # 학습 MAE, 검증 MAE 계산\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mae_valid = mean_absolute_error(y_valid, y_valid_pred)\n",
    "    print(\"학습 결과..! 🎉\")\n",
    "    print(f\"Train MAE: {mae_train:.4f}, Valid MAE: {mae_valid:.4f}\")\n",
    "\n",
    "    return mae_train, mae_valid\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Optuna를 이용하여 Hyperparameter 튜닝을 수행하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): 탐색하려는 하이퍼파라미터 범위를 설정하는 클래스\n",
    "\n",
    "    Returns:\n",
    "        float: 현재 Trial에서 선택한 하이퍼파라미터셋으로 학습한 모델의 검증 MAE\n",
    "    \"\"\"\n",
    "    # n_d를 먼저 제안합니다.\n",
    "    n_d = trial.suggest_int(\"n_d\", 8, 64)\n",
    "    params = {\n",
    "        \"n_d\": n_d,\n",
    "        \"n_a\": n_d,  # n_a는 n_d와 동일하게 설정\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
    "        \"n_independent\": 2, # 필요하면 3, 4로 늘려본다\n",
    "        \"n_shared\": 2, # 필요하면 3, 4로 늘려본다\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 0.001, 0.01),\n",
    "        \"optimizer_fn\": torch.optim.Adam,\n",
    "        \"optimizer_params\": dict(lr=trial.suggest_float(\"learning_rate\", 0.001, 0.01)),\n",
    "        \"verbose\": 1,\n",
    "        \"device_name\" : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"seed\" : 42\n",
    "    }\n",
    "\n",
    "    # TabNet 모델 생성\n",
    "    model = TabNetRegressor(**params)\n",
    "    \n",
    "    # 모델 학습 및 MAE 계산\n",
    "    mae_train, mae_valid = train_model(model, X, y)\n",
    "    print(\"Optuna 결과..! 💫\")\n",
    "    print(f\"Trial {trial.number}: Train MAE: {mae_train:.4f}, Valid MAE: {mae_valid:.4f}\")\n",
    "    \n",
    "    return mae_valid #, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 실험 세팅 및 실행\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# 최적 하이퍼파라미터 출력\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "print(\"Best MAE: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 history 시각화\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna로 튜닝한 파라미터로 모델 재학습\n",
    "best_params = {\n",
    "    \"n_d\": 62,\n",
    "    \"n_a\": 62,  # n_a는 n_d와 동일하게 설정\n",
    "    \"n_steps\": 8,\n",
    "    \"gamma\": 1.2533699284830764,\n",
    "    \"n_independent\": 2, # 필요하면 3, 4로 늘려본다.\n",
    "    \"n_shared\": 2, # 필요하면 3, 4로 늘려본다.\n",
    "    \"lambda_sparse\": 0.009596303461374517,\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=0.009855066118782934),\n",
    "    \"verbose\": 1,\n",
    "    \"device_name\" : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\" : 42\n",
    "}\n",
    "\n",
    "best_model: object = TabNetRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train, \n",
    "    eval_set=[(X_train, y_train),(X_valid, y_valid)], \n",
    "    eval_name=[\"train\", \"valid\"],\n",
    "    eval_metric=[\"mae\"],\n",
    "    loss_fn=torch.nn.L1Loss(),\n",
    "    max_epochs=200, \n",
    "    patience=10,\n",
    "    batch_size=2048,\n",
    "    drop_last=False,\n",
    "    warm_start=True  # warm start 활성화\n",
    ")\n",
    "print(\"모델 학습이 완료됐습니다. ⏲\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 학습한 히스토리 확인\n",
    "# model.history.history.keys()\n",
    "\n",
    "# 손실 그래프 그리기\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(best_model.history[\"loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # 학습률 그래프 그리기 (현재는 학습률이 고정이라 직선입니다.)\n",
    "# # model.history에서 learning rate 값을 가져옵니다.\n",
    "# lr: list[float] = model.history['lr']\n",
    "# epochs: range = range(1, len(lr) + 1)\n",
    "\n",
    "# # learning rate 그래프를 그립니다.\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# plt.plot(epochs, lr, color='green')\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Learning Rate\")\n",
    "# plt.title(\"Learning Rate over Epochs\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# MAE 그래프 그리기\n",
    "# best_model.history에서 train MAE와 valid MAE 값을 가져옵니다.\n",
    "train_mae: list[float] = best_model.history[\"train_mae\"]\n",
    "valid_mae: list[float] = best_model.history[\"valid_mae\"]\n",
    "epochs: range = range(1, len(train_mae) + 1)\n",
    "\n",
    "# train MAE와 valid MAE 그래프를 그립니다.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_mae, label=\"Train MAE\", color=\"blue\")\n",
    "plt.plot(epochs, valid_mae, label=\"Valid MAE\", color=\"red\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and Valid MAE over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate & Save File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error 내용**\n",
    "\n",
    "RuntimeError: CUDA error: device-side assert triggered 에러는 주로 GPU에서 데이터 처리 중 발생하는 오류로, 다음과 같은 원인이 있을 수 있습니다:\n",
    "\n",
    "- 잘못된 입력 데이터 형식: 입력 데이터가 모델이 기대하는 형식과 일치하지 않거나 잘못된 값을 포함할 수 있습니다. 예를 들어, TabNet 모델에 대한 입력 데이터는 float 타입이어야 하며, 정수 인덱스 또는 NaN 값이 없어야 합니다.\n",
    "\n",
    "- 타겟 변수의 범위 문제: 예측할 때 타겟 변수가 예상 범위를 벗어나는 경우에도 이런 오류가 발생할 수 있습니다.\n",
    "\n",
    "- 배치 크기 문제: 배치 크기가 너무 크거나 너무 작아서 발생할 수 있습니다.\n",
    "\n",
    "- CUDA 드라이버 문제: 사용 중인 CUDA 버전이 PyTorch와 호환되지 않거나, 드라이버 업데이트가 필요할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA 런타임 블록 설정**\n",
    "\n",
    "오류 위치 정확히 확인하기 위해 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드에 뜨는 에러 수정\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\" # CUDA 설정 버전: Jupyter 환경\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # torch Error log를 더 자세히 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 원래 데이터 쓰는 사람용 (test_data에서 불필요한 변수 drop: 로그변환한 변수)\n",
    "X_test: pd.DataFrame = test_data.drop(columns=[\"index\", \"log_area_m2\", \"log_subway_distance\", \"log_school_distance\", \"log_park_distance\", \"log_leader_distance\"])\n",
    "X_test = X_test.values.astype(np.float32) # float32 넘파이 배열로 변환\n",
    "\n",
    "# 2. 로그변환한 데이터 쓰는 사람용 (test_data에서 불필요한 변수 drop: 로그변환하기 전 변수)\n",
    "# X_test: pd.DataFrame = test_data.drop(columns=[\"index\", \"area_m2\", \"nearest_subway_distance\", \"nearest_school_distance\", \"nearest_park_distance\", \"nearest_leader_distance\"])\n",
    "# X_test = X_test.values.astype(np.float32) # float32 넘파이 배열로 변환\n",
    "\n",
    "# 3. 다빈, 성택이 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 X) & 4. 영균이 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 O)\n",
    "# X_test: pd.DataFrame = test_data[selected_cols]\n",
    "# X_test = X_test.values.astype(np.float32) # float32 넘파이 배열로 변환\n",
    "\n",
    "\n",
    "# X_test에 대한 예측 수행 후, 예측 결과를 csv 파일로 저장\n",
    "# 1. 원래 데이터 쓰는 사람용 & 3. 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 X)\n",
    "y_pred = best_model.predict(X_test)\n",
    "sample_submission[\"deposit\"] = y_pred\n",
    "sample_submission.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "# 2. 로그변환한 데이터 쓰는 사람용 & 4. 선택한 feature (로그변환 데이터 포함 / deposit 로그변환 O)\n",
    "# save_csv(best_model, X_test, sample_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_pred.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"deposit\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
