{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = \"~/house/data\"\n",
    "train_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "test_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "sample_submission: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금리, 지하철, 학교, 공원 정보 불러오기\n",
    "interest_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"interestRate.csv\"))\n",
    "subway_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"subwayInfo.csv\"))\n",
    "school_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"schoolinfo.csv\"))\n",
    "park_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"parkInfo.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 금리 데이터 병합\n",
    "* `interest_data`: 2018년 12월 ~ 2024년 5월까지의 금리\n",
    "* 계약 연월 기준으로 `interest_data`를 `train_data`로 병합 (2019년 4월 ~ 2023년 12월)\n",
    "* 계약 연월 기준으로 `interest_data`를 `test_data`로 병합 (2024년 1월 ~ 2024년 6월)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계약 연월 기준으로 interest_data를 train_data로 병합\n",
    "merged_train = pd.merge(train_data, interest_data, left_on=\"contract_year_month\", right_on=\"year_month\", how=\"left\")\n",
    "merged_train = merged_train.drop(columns=[\"year_month\"])\n",
    "merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = pd.merge(test_data, interest_data, left_on=\"contract_year_month\", right_on=\"year_month\", how=\"left\")\n",
    "merged_test = merged_test.drop(columns=[\"year_month\"])\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금리 결측치 개수 확인 (2024년 6월)\n",
    "merged_test[\"interest_rate\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최단거리 데이터 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn의 BallTree를 활용한 haversine 거리 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_distance_haversine(\n",
    "    train_data: pd.DataFrame, \n",
    "    loc_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"건물과 지하철/학교/공원 사이의 haversine 거리를 계산하는 함수\n",
    "\n",
    "    Args:\n",
    "        train_data (pd.DataFrame): 학습(훈련) 또는 테스트 데이터프레임\n",
    "        loc_df (pd.DataFrame): 위도, 경도를 column으로 갖는 데이터프레임\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: index, 위도, 경도, haversine 거리를 column으로 갖는 반환\n",
    "    \"\"\"\n",
    "    # degree->radian 값으로 변환 for 삼각함수\n",
    "    train_coords = np.radians(train_data[[\"latitude\", \"longitude\"]].values)\n",
    "    loc_coords = np.radians(loc_df[[\"latitude\", \"longitude\"]].values)\n",
    "    \n",
    "    # Ball Tree 생성 \n",
    "    tree = BallTree(loc_coords, metric=\"haversine\")\n",
    "\n",
    "    distances, indices = tree.query(train_coords, k=1) # 가까운 1 지점만 \n",
    "    distances_meter = distances * 6371000 # 단위를 meter로 변환\n",
    "\n",
    "    closest_coords = loc_df[[\"latitude\", \"longitude\"]].iloc[indices.flatten()].values # 가까운 지점 좌표\n",
    "\n",
    "    # index, 최단거리, 최단거리에 해당하는 지점의 위도, 경도로 이루어진 데이터프레임 생성\n",
    "    result_df = pd.DataFrame({\n",
    "        \"index\" : train_data.index,\n",
    "        \"closest_distance\" : distances_meter.flatten(),\n",
    "        \"closest_latitude\" : closest_coords[:, 0],\n",
    "        \"closest_longtitude\" : closest_coords[:, 1]\n",
    "    })\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subway 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_result = find_closest_distance_haversine(train_data, subway_data)\n",
    "subway_result.columns = [\"index\", \"nearest_subway_distance\", \"nearest_subway_latitude\", \"nearest_subway_longtitude\"]\n",
    "train_data = pd.merge(train_data, subway_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_result = find_closest_distance_haversine(test_data, subway_data)\n",
    "subway_result.columns = [\"index\", \"nearest_subway_distance\", \"nearest_subway_latitude\", \"nearest_subway_longtitude\"]\n",
    "test_data = pd.merge(test_data, subway_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### school 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_result = find_closest_distance_haversine(train_data, school_data)\n",
    "school_result.columns = [\"index\", \"nearest_school_distance\", \"nearest_school_latitude\", \"nearest_school_longtitude\"]\n",
    "train_data = pd.merge(train_data, school_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_result = find_closest_distance_haversine(test_data, school_data)\n",
    "school_result.columns = [\"index\", \"nearest_school_distance\", \"nearest_school_latitude\", \"nearest_school_longtitude\"]\n",
    "test_data = pd.merge(test_data, school_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### park 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_result = find_closest_distance_haversine(train_data, park_data)\n",
    "park_result.columns = [\"index\", \"nearest_park_distance\", \"nearest_park_latitude\", \"nearest_park_longtitude\"]\n",
    "train_data = pd.merge(train_data, park_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_result = find_closest_distance_haversine(test_data, park_data)\n",
    "park_result.columns = [\"index\", \"nearest_park_distance\", \"nearest_park_latitude\", \"nearest_park_longtitude\"]\n",
    "test_data = pd.merge(test_data, park_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 병합한 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = merged_train.columns.drop(\"interest_rate\").tolist() # 병합 기준이 될 column 리스트\n",
    "train_data = pd.merge(merged_train, train_data, on=on, how=\"left\")\n",
    "# train_data = train_data.drop(columns=[\"index\"])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = merged_test.columns.drop(\"interest_rate\").tolist() # 병합 기준이 될 column 리스트\n",
    "test_data = pd.merge(merged_test, test_data, on=on, how=\"left\")\n",
    "# test_data = test_data.drop(columns=[\"index\"])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 탐지 함수\n",
    "def find_outliers(data: pd.Series) -> pd.Series:\n",
    "    \"\"\"안 울타리(inner fence) 밖에 있는 데이터(이상치, outlier)를 반환하는 함수\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): 이상치 탐지를 하고싶은 데이터의 column\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 이상치에 해당하는 데이터 Series 반환\n",
    "    \"\"\"\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data < lower_bound) | (data > upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = train_data.copy()\n",
    "eda_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 결측치 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 확인 결과 없음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열에서 누락된 값의 수를 계산\n",
    "missing_values = eda_df.isnull().sum()\n",
    "\n",
    "# 누락된 값의 백분율 계산\n",
    "missing_percentage = (missing_values / len(eda_df)) * 100\n",
    "\n",
    "# 누락된 값 비율을 기준으로 열 정렬\n",
    "sorted_missing_percentage = missing_percentage.sort_values(ascending=False)\n",
    "sorted_missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열에서 누락된 값의 수를 계산\n",
    "missing_values = test_data.isnull().sum()\n",
    "\n",
    "# 누락된 값의 백분율 계산\n",
    "missing_percentage = (missing_values / len(test_data)) * 100\n",
    "\n",
    "# 누락된 값 비율을 기준으로 열 정렬\n",
    "sorted_missing_percentage = missing_percentage.sort_values(ascending=False)\n",
    "sorted_missing_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 상관관계 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deposit과 상관관계가 높은 feature 확인\n",
    "\n",
    ": area_m2, nearest_subway_distance가 유의미한 상관관계(앞은 음, 뒤는 양의 상관관계)를 가진다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.drop(columns=\"index\", inplace=False).corr()[\"deposit\"].abs().sort_values(ascending =False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. area_m2 범주에 따른 deposit  분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 면적 범주화 함수\n",
    "def categorize_area(x):\n",
    "    range_start = (x // 50) * 50\n",
    "    range_end = range_start + 49\n",
    "    return f\"{range_start} - {range_end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"area_m2_category\"] = eda_df[\"area_m2\"].apply(categorize_area)\n",
    "print(\"범주화 결과 :\", eda_df[\"area_m2_category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_counts = eda_df[\"area_m2_category\"].value_counts().reset_index()\n",
    "trade_counts.columns = [\"area_m2_category\", \"transaction_count\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=trade_counts, x=\"area_m2_category\", y=\"transaction_count\")\n",
    "plt.title(\"Number of Transactions by area_m2_category\")\n",
    "plt.xlabel(\"area_m2_category\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 50 - 99 범주 거래량이 가장 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=eda_df, x=\"area_m2_category\", y=\"deposit\")\n",
    "plt.title(\"area_m2_category vs deposit\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 300 m² 범주에서 보증금이 1,000,000을 넘어가는 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deposit_outliers = find_outliers(train_data[\"deposit\"])\n",
    "# train_data_cleaned = train_data[~train_data[\"deposit\"].isin(deposit_outliers)]\n",
    "\n",
    "# print(\"전체 데이터 개수:\", train_data.shape[0])\n",
    "# print(\"이상치 개수:\", deposit_outliers.count())\n",
    "# print(\"정상 데이터 개수:\", train_data_cleaned.shape[0])\n",
    "\n",
    "# 특정 값 이상 제거 (1,000,000 이상)\n",
    "eda_df_cleaned = eda_df[eda_df[\"deposit\"] < 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"0.0 - 49.0\", \"50.0 - 99.0\", \"100.0 - 149.0\", \"150.0 - 199.0\", \"200.0 - 249.0\", \"250.0 - 299.0\", \"300.0 - 349.0\"]\n",
    "eda_df_cleaned[\"area_m2_category\"] = pd.Categorical(eda_df_cleaned[\"area_m2_category\"], categories=categories, ordered=True)\n",
    "mean_deposit = eda_df_cleaned.groupby(\"area_m2_category\")[\"deposit\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=mean_deposit, x=\"area_m2_category\", y=\"deposit\", marker=\"o\")\n",
    "plt.title(\"Average Deposit by area_m2_category\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 면적이 증가함에 따라 보증금이 상승하는 경향 (양의 상관관계)\n",
    "- 구간별 상승률이 일정하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 절대적인 변화량 계산\n",
    "mean_deposit[\"absolute_change\"] = mean_deposit[\"deposit\"] - mean_deposit[\"deposit\"].shift(1)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=mean_deposit, x=\"area_m2_category\", y=\"absolute_change\")\n",
    "plt.title(\"Average Deposit Absolute Change by area_m2_category\")\n",
    "plt.ylabel(\"Absolute Change\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적으로 변화량은 비슷\n",
    "- 150-199 ~ 200-249 사이 변화량 눈에 띄게 상승 (60평 전후)\n",
    "- 250-249 ~ 300-349 사이 변화량 눈에 띄게 감소 (90평 전후)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.3 Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 area_m2와 deposit은 양의 상관관계를 가지지만,\n",
    "\n",
    "구간별로 변화량에 차이가 있어 추가 변수로 활용해도 좋을 듯 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 area_m2와 상관관계가 높은 변수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.drop(columns=[\"index\", \"area_m2_category\"], inplace=False).corr()[\"area_m2\"].abs().sort_values(ascending =False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시계열 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 계약 연도별 및 월별 deposit 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 이벤트 발생에 따른 변화가 있어 보이지만, 외부 데이터라 활용 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df[\"contract_year\"] = eda_df[\"contract_year_month\"].astype(str).str[:4].astype(int)\n",
    "eda_df[\"contract_month\"] = eda_df[\"contract_year_month\"].astype(str).str[4:6].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계약 월별 평균 전세가 계산\n",
    "monthly_avg = eda_df.groupby([\"contract_year\", \"contract_month\"])[\"deposit\"].mean().reset_index()\n",
    "\n",
    "# 계약 연도, 월, 일을 결합하여 새로운 datetime 컬럼 생성\n",
    "monthly_avg[\"contract_date\"] = pd.to_datetime(monthly_avg[\"contract_year\"].astype(str) + \"-\" + monthly_avg[\"contract_month\"].astype(str) + \"-01\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_avg[\"contract_date\"], monthly_avg[\"deposit\"], marker=\"o\")\n",
    "plt.title(\"Monthly Average Deposit Over Time\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Average Deposit\")\n",
    "plt.grid()\n",
    "plt.axvline(pd.Timestamp(\"2020-01-01\"), color=\"red\", linestyle=\"--\", label=\"COVID-19 Start\")\n",
    "plt.axvline(pd.Timestamp(\"2022-01-01\"), color=\"red\", linestyle=\"--\", label=\"COVID-19 End\")\n",
    "plt.axvline(pd.Timestamp(\"2022-03-09\"), color=\"green\", linestyle=\"--\", label=\"President Election\") # 부동산 규제 완화\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.시즌별 deposit 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대학입학 시즌 등 시즌별 변화가 있을 지 보았지만, 뚜렷한 변화는 안 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계절을 나타내는 함수 정의\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\"\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "eda_df.groupby(eda_df[\"contract_month\"].apply(get_season))[\"deposit\"].mean().plot(kind=\"bar\")\n",
    "plt.title(\"Average Deposit by Season\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Average Deposit\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. 지역별 범주화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1. 지역별 deposit 분포 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=eda_df, x=\"longitude\", y=\"latitude\", hue=\"deposit\", palette=\"viridis\", size=\"area_m2\", sizes=(20, 200), alpha=0.2)\n",
    "\n",
    "plt.title(\"Deposit by Location\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1. area_m2 대비 deposit으로 분포 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 면적 대비 전세가 계산\n",
    "eda_df[\"price_per_area\"] = eda_df[\"deposit\"] / eda_df[\"area_m2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = eda_df[\"price_per_area\"].quantile(0.25)\n",
    "Q2 = eda_df[\"price_per_area\"].quantile(0.5)\n",
    "Q3 = eda_df[\"price_per_area\"].quantile(0.75)\n",
    "\n",
    "def categorize_price(price_per_area):\n",
    "    if price_per_area <= Q1:\n",
    "        return \"cheap\"\n",
    "    elif price_per_area <= Q2:\n",
    "        return \"normal\"\n",
    "    elif price_per_area <= Q3:\n",
    "        return \"expensive\"\n",
    "    else:\n",
    "        return \"super\"\n",
    "\n",
    "eda_df[\"price_category\"] = eda_df[\"price_per_area\"].apply(categorize_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=eda_df, x=\"longitude\", y=\"latitude\", hue=\"price_category\", palette=\"viridis\", size=\"price_per_area\", sizes=(20, 200), alpha=0.2)\n",
    "\n",
    "plt.title(\"Deposit by Location\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서울 중심 지역으로 갈수록 면적 대비 전세가 높아지는 것 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2. 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "price_dummies = pd.get_dummies(eda_df[\"price_category\"], prefix=\"category\")\n",
    "eda_cluster = pd.concat([eda_df[[\"longitude\", \"latitude\", \"price_per_area\"]], price_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "sse = []\n",
    "k_values = range(1, 15)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(eda_cluster)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, sse, marker=\"o\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.xticks(k_values)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means 클러스터링 적용\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "eda_df[\"kmeans_cluster\"] = kmeans.fit_predict(eda_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스 플롯 시각화\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(data=eda_df, x=\"kmeans_cluster\", y=\"deposit\")\n",
    "plt.title(\"deposit by K-means Clusters\")\n",
    "plt.xlabel(\"kmeans_cluster\")\n",
    "plt.ylabel(\"deposit\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=eda_df, x=\"longitude\", y=\"latitude\", hue=\"kmeans_cluster\", palette=\"viridis\", alpha=0.2, size=\"price_per_area\", sizes=(20, 200))\n",
    "plt.title(\"Location Clustering with Price per Area\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN(Density-Based Spatial Clustering of Applications with Noise)은 밀도 기반 클러스터링 알고리즘으로, 데이터 포인트의 밀도를 기준으로 클러스터를 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # eps와 min_samples는 조정 가능\n",
    "eda_df[\"dbscan_cluster\"] = dbscan.fit_predict(eda_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스 플롯 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=eda_df, x=\"dbscan_cluster\", y=\"deposit\")\n",
    "plt.title(\"deposit by DBSCAN Clusters\")\n",
    "plt.xlabel(\"dbscan_cluster\")\n",
    "plt.ylabel(\"deposit\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=eda_df, x=\"longitude\", y=\"latitude\", hue=\"dbscan_cluster\", palette=\"viridis\", alpha=0.2, size=\"price_per_area\", sizes=(20, 200))\n",
    "plt.title(\"Location Clustering with Price per Area\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4. Agglomerative 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative Clustering은 계층적 군집화 방법으로, 각 데이터 포인트를 개별 클러스터로 시작하여 점차적으로 클러스터를 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative Clustering 적용\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "eda_df[\"agg_cluster\"] = agg_clustering.fit_predict(eda_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스 플롯 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=eda_df, x=\"agg_cluster\", y=\"deposit\")\n",
    "plt.title(\"deposit by DBSCAN Clusters\")\n",
    "plt.xlabel(\"agg_cluster\")\n",
    "plt.ylabel(\"deposit\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산점도 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=eda_df, x=\"longitude\", y=\"latitude\", hue=\"agg_cluster\", palette=\"viridis\", alpha=0.2, size=\"price_per_area\", sizes=(20, 200))\n",
    "plt.title(\"Location Clustering with Price per Area\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. contract_type별 평균 deposit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_type_avg = eda_df.groupby(\"contract_type\")[\"deposit\"].mean()\n",
    "print(contract_type_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크게 두드러지는 차이 없는 것 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = train_data.copy()\n",
    "test_tmp = test_data.copy()\n",
    "# train_data = train_tmp.copy()\n",
    "# test_data = test_tmp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. built_year > 2024 행 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before train :\", train_data.shape)\n",
    "train_data = train_data[train_data[\"built_year\"] < 2024]\n",
    "print(\"after train :\", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 음수 층수 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"before train :\", train_data.shape)\n",
    "# train_data = train_data[train_data[\"floor\"] >= 0]\n",
    "# print(\"after train :\", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 사용하지 않는 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"index\", \"contract_type\", \"age\", \"interest_rate\", \"nearest_subway_latitude\", \"nearest_subway_longtitude\", \"nearest_school_latitude\", \"nearest_school_longtitude\", \"nearest_park_latitude\", \"nearest_park_longtitude\"]\n",
    "\n",
    "train_data.drop(columns=cols, inplace=True)\n",
    "test_data.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. area_m2_category 컬럼 추가 (EDA-2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_area(x):\n",
    "    range_start = (x // 50) * 50\n",
    "    range_end = range_start + 49\n",
    "    return f\"{range_start} - {range_end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_m2_category = pd.get_dummies(train_data[\"area_m2\"].apply(categorize_area), prefix=\"category\") # One-Hot Encoding\n",
    "train_data = pd.concat([train_data, area_m2_category], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_m2_category = pd.get_dummies(test_data[\"area_m2\"].apply(categorize_area), prefix=\"category\") # One-Hot Encoding\n",
    "test_data = pd.concat([test_data, area_m2_category], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data[\"category_300.0 - 349.0\"] != True]\n",
    "train_data.drop(columns=[\"category_300.0 - 349.0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"log_deposit\"] = np.log1p(train_data[\"deposit\"])\n",
    "train_data[\"log_area_m2\"] = np.log1p(train_data[\"area_m2\"])\n",
    "train_data[\"log_school_distance\"] = np.log1p(train_data[\"nearest_school_distance\"])\n",
    "train_data[\"log_park_distance\"] = np.log1p(train_data[\"nearest_park_distance\"])\n",
    "train_data[\"log_subway_distance\"] = np.log1p(train_data[\"nearest_subway_distance\"])\n",
    "\n",
    "train_data.drop(columns=[\"area_m2\", \"floor\", \"nearest_school_distance\", \"nearest_park_distance\", \"nearest_subway_distance\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"log_area_m2\"] = np.log1p(test_data[\"area_m2\"])\n",
    "test_data[\"log_school_distance\"] = np.log1p(test_data[\"nearest_school_distance\"])\n",
    "test_data[\"log_park_distance\"] = np.log1p(test_data[\"nearest_park_distance\"])\n",
    "test_data[\"log_subway_distance\"] = np.log1p(test_data[\"nearest_subway_distance\"])\n",
    "\n",
    "test_data.drop(columns=[\"area_m2\", \"floor\", \"nearest_school_distance\", \"nearest_park_distance\", \"nearest_subway_distance\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"deposit\", \"log_deposit\"], inplace=False)\n",
    "y = train_data[[\"deposit\", \"log_deposit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.drop(columns=[\"deposit\"], inplace=True)\n",
    "y_valid.drop(columns=[\"log_deposit\"], inplace=True)\n",
    "print(f\"y_train: {y_train.columns}\")\n",
    "print(f\"y_valid: {y_valid.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "#         \"tree_method\": \"hist\",\n",
    "#         \"device\": \"cuda\",\n",
    "#         \"random_state\": 42\n",
    "#     }\n",
    "    \n",
    "#     model = xgb.XGBRegressor(**params)\n",
    "    \n",
    "#     score = cross_val_score(model, X_train, y_train, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
    "#     return -score.mean()\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler(seed=42)\n",
    "# xgb_study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "# xgb_study.optimize(objective, n_trials=50)\n",
    "# print(\"Best parameters for XGBoost: \", xgb_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\"n_estimators\": 288, \"learning_rate\": 0.11112043349923437, \"max_depth\": 10, \"subsample\": 0.7511206505586165}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화된 하이퍼파라미터를 반영한 모델 정의\n",
    "best_model = xgb.XGBRegressor(**best_params, tree_method=\"gpu_hist\", gpu_id=0, random_state=42)\n",
    "\n",
    "scores = cross_val_score(best_model, X_train, y_train, cv=kf, scoring=\"neg_mean_absolute_error\")\n",
    "print(f\"Voting Regressor: Mean MAE = {-scores.mean():.4f}, Std = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "y_pred_log = best_model.predict(X_valid)\n",
    "y_pred = np.expm1(y_pred_log) # 지수변환 (로그변환의 역변환)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "print(f\"Final Model MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_log = best_model.predict(X_test)\n",
    "y_test = np.expm1(y_test_log) # 지수변환 (로그변환의 역변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지수변환 전/후 예측값 히스토그램 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.histplot(y_test_log, ax=axes[0])\n",
    "sns.histplot(y_test, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"deposit\"] = y_test\n",
    "sample_submission.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
