{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.load_dataset import load_dataset\n",
    "from data.merge_dataset import merge_dataset\n",
    "from data.feature_engineering import *\n",
    "from model.inference import save_csv\n",
    "from model.feature_select import select_features\n",
    "from model.data_split import split_features_and_target\n",
    "from model.log_transformation import apply_log_transformation\n",
    "from model.model_train import set_model, optuna_train\n",
    "#from model.TreeModel import XGBoost\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import optuna\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 데이터 불러오기\n",
    "train_data, test_data, sample_submission, interest_data, subway_data, school_data, park_data = load_dataset()\n",
    "# 기존 데이터에 새로운 feature들을 병합한 데이터프레임 불러오기\n",
    "train_data, test_data = merge_dataset(train_data, test_data, interest_data, subway_data, school_data, park_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 중복도 낮은 행 삭제\n",
    "groups = train_data.groupby([\"latitude\", \"longitude\"])[\"index\"].count()\n",
    "conditioned_groups_index = groups[(groups >= 2) & (groups <= 5)].index # 이 범위를 파라미터로 조정하는걸로\n",
    "small_groups = train_data[\n",
    "    train_data[\"latitude\"].isin(conditioned_groups_index.get_level_values(0)) &\n",
    "    train_data[\"longitude\"].isin(conditioned_groups_index.get_level_values(1))\n",
    "]\n",
    "train_data.drop(small_groups.index, axis=0, inplace=True)\n",
    "\n",
    "# built_year > 2024 행 삭제\n",
    "train_data = train_data[train_data[\"built_year\"] < 2024]\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "feature_columns = [\"latitude\", \"longitude\"]\n",
    "coords = train_data[feature_columns]\n",
    "\n",
    "# ClusteringModel 클래스 인스턴스 생성\n",
    "clustering_model = ClusteringModel(data=coords)\n",
    "kmeans_model = clustering_model.kmeans_clustering(n_clusters=25, \n",
    "                                                train_data=train_data, \n",
    "                                                test_data=test_data, \n",
    "                                                feature_columns=feature_columns, \n",
    "                                                label_column=\"region\")\n",
    "\n",
    "region_mean_prices = train_data.groupby(\"region\")[\"deposit\"].mean().reset_index()\n",
    "region_mean_prices.columns = [\"region\", \"mean_deposit\"]\n",
    "region_mean_prices[\"mean_deposit_category\"] = region_mean_prices[\"mean_deposit\"] // 10000\n",
    "\n",
    "# train_data와 region_mean_prices 병합\n",
    "train_data = train_data.merge(region_mean_prices, on=\"region\", how=\"left\")\n",
    "test_data = test_data.merge(region_mean_prices, on=\"region\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = apply_log_transformation(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature select**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, test_data = select_features(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_data split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_features_and_target(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'area_m2', 'contract_year_month', 'contract_day',\n",
       "       'contract_type', 'floor', 'built_year', 'latitude', 'longitude', 'age',\n",
       "       'interest_rate', 'nearest_subway_distance', 'nearest_subway_latitude',\n",
       "       'nearest_subway_longitude', 'nearest_school_distance',\n",
       "       'nearest_school_latitude', 'nearest_school_longitude',\n",
       "       'nearest_park_distance', 'nearest_park_latitude',\n",
       "       'nearest_park_longitude', 'nearest_subway_num', 'nearest_school_num',\n",
       "       'nearest_park_num', 'num_of_subways_within_radius',\n",
       "       'num_of_schools_within_radius', 'num_of_parks_within_radius', 'region',\n",
       "       'mean_deposit', 'mean_deposit_category', 'log_area_m2',\n",
       "       'log_school_distance', 'log_park_distance', 'log_subway_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['deposit', 'log_deposit'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabnet**\n",
    "- 테이블 데이터에서도 딥러닝이 잘 동작할 수 있게 만들어진 모델\n",
    "- 자동으로 중요한 features를 선택하기 떄문에 feature select부분은 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna + kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8, 64),\n",
    "        \"n_a\": trial.suggest_int(\"n_a\", 8, 64),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 0.0001, 0.01),\n",
    "        \"optimizer_params\": dict(lr=trial.suggest_float(\"learning_rate\", 0.001, 0.01))\n",
    "    }\n",
    "    \n",
    "    # K-Fold 교차 검증\n",
    "    cv = 5\n",
    "    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    model = TabNetRegressor(**params)\n",
    "    y_pred = cross_val_predict(\n",
    "        model,\n",
    "        X.values, \n",
    "        y[\"log_deposit\"].values.reshape(-1, 1),\n",
    "        cv = kfold,\n",
    "        method=\"predict\",\n",
    "        fit_params={\"max_epochs\": 5}\n",
    "    )\n",
    "    \n",
    "    y_pred = np.expm1(y_pred)\n",
    "        \n",
    "    # MAE 계산\n",
    "    mae = mean_absolute_error(y[\"deposit\"].values, y_pred) \n",
    "    print(f\"Trial {trial.number}: MAE = {mae}\")\n",
    "\n",
    "    # 교차 검증 후 MAE 반환\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 00:40:04,725] A new study created in memory with name: no-name-dad22c9f-d7f3-4031-8448-182b9d41f357\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:73: FutureWarning: `fit_params` is deprecated and will be removed in version 1.6. Pass parameters via `params` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92112 |  0:01:24s\n",
      "epoch 1  | loss: 0.11554 |  0:02:50s\n",
      "epoch 2  | loss: 0.1012  |  0:04:14s\n",
      "epoch 3  | loss: 0.09596 |  0:05:39s\n",
      "epoch 4  | loss: 0.08746 |  0:07:04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.90485 |  0:01:28s\n",
      "epoch 1  | loss: 0.12519 |  0:02:57s\n",
      "epoch 2  | loss: 0.12009 |  0:04:29s\n",
      "epoch 3  | loss: 0.1069  |  0:05:56s\n",
      "epoch 4  | loss: 0.09982 |  0:07:23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.90966 |  0:01:33s\n",
      "epoch 1  | loss: 0.11886 |  0:03:06s\n",
      "epoch 2  | loss: 0.11324 |  0:04:41s\n",
      "epoch 3  | loss: 0.10262 |  0:06:15s\n",
      "epoch 4  | loss: 0.09738 |  0:07:50s\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best parameters for Tabnet: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = TabNetRegressor(**best_params)\n",
    "best_model.fit(X.values, y[\"log_deposit\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(best_model, test_data, sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
