{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = \"~/house/data\"\n",
    "train_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "test_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "sample_submission: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금리, 지하철, 학교, 공원 정보 불러오기\n",
    "interest_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"interestRate.csv\"))\n",
    "subway_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"subwayInfo.csv\"))\n",
    "school_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"schoolinfo.csv\"))\n",
    "park_data: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"parkInfo.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 금리 데이터 병합\n",
    "* `interest_data`: 2018년 12월 ~ 2024년 5월까지의 금리\n",
    "* 계약 연월 기준으로 `interest_data`를 `train_data`로 병합 (2019년 4월 ~ 2023년 12월)\n",
    "* 계약 연월 기준으로 `interest_data`를 `test_data`로 병합 (2024년 1월 ~ 2024년 6월)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계약 연월 기준으로 interest_data를 train_data로 병합\n",
    "merged_train = pd.merge(train_data, interest_data, left_on=\"contract_year_month\", right_on=\"year_month\", how=\"left\")\n",
    "merged_train = merged_train.drop(columns=[\"year_month\"])\n",
    "merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = pd.merge(test_data, interest_data, left_on=\"contract_year_month\", right_on=\"year_month\", how=\"left\")\n",
    "merged_test = merged_test.drop(columns=[\"year_month\"])\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금리 결측치 개수 확인 (2024년 6월)\n",
    "merged_test[\"interest_rate\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최단거리 데이터 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn의 BallTree를 활용한 haversine 거리 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_distance_haversine(\n",
    "    train_data: pd.DataFrame, \n",
    "    loc_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"건물과 지하철/학교/공원 사이의 haversine 거리를 계산하는 함수\n",
    "\n",
    "    Args:\n",
    "        train_data (pd.DataFrame): 학습(훈련) 또는 테스트 데이터프레임\n",
    "        loc_df (pd.DataFrame): 위도, 경도를 column으로 갖는 데이터프레임\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: index, 위도, 경도, haversine 거리를 column으로 갖는 반환\n",
    "    \"\"\"\n",
    "    # degree->radian 값으로 변환 for 삼각함수\n",
    "    train_coords = np.radians(train_data[[\"latitude\", \"longitude\"]].values)\n",
    "    loc_coords = np.radians(loc_df[[\"latitude\", \"longitude\"]].values)\n",
    "    \n",
    "    # Ball Tree 생성 \n",
    "    tree = BallTree(loc_coords, metric=\"haversine\")\n",
    "\n",
    "    distances, indices = tree.query(train_coords, k=1) # 가까운 1 지점만 \n",
    "    distances_meter = distances * 6371000 # 단위를 meter로 변환\n",
    "\n",
    "    closest_coords = loc_df[[\"latitude\", \"longitude\"]].iloc[indices.flatten()].values # 가까운 지점 좌표\n",
    "\n",
    "    # index, 최단거리, 최단거리에 해당하는 지점의 위도, 경도로 이루어진 데이터프레임 생성\n",
    "    result_df = pd.DataFrame({\n",
    "        \"index\" : train_data.index,\n",
    "        \"closest_distance\" : distances_meter.flatten(),\n",
    "        \"closest_latitude\" : closest_coords[:, 0],\n",
    "        \"closest_longtitude\" : closest_coords[:, 1]\n",
    "    })\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subway 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_result = find_closest_distance_haversine(train_data, subway_data)\n",
    "subway_result.columns = [\"index\", \"nearest_subway_distance\", \"nearest_subway_latitude\", \"nearest_subway_longtitude\"]\n",
    "train_data = pd.merge(train_data, subway_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_result = find_closest_distance_haversine(test_data, subway_data)\n",
    "subway_result.columns = [\"index\", \"nearest_subway_distance\", \"nearest_subway_latitude\", \"nearest_subway_longtitude\"]\n",
    "test_data = pd.merge(test_data, subway_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### school 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_result = find_closest_distance_haversine(train_data, school_data)\n",
    "school_result.columns = [\"index\", \"nearest_school_distance\", \"nearest_school_latitude\", \"nearest_school_longtitude\"]\n",
    "train_data = pd.merge(train_data, school_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_result = find_closest_distance_haversine(test_data, school_data)\n",
    "school_result.columns = [\"index\", \"nearest_school_distance\", \"nearest_school_latitude\", \"nearest_school_longtitude\"]\n",
    "test_data = pd.merge(test_data, school_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### park 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_result = find_closest_distance_haversine(train_data, park_data)\n",
    "park_result.columns = [\"index\", \"nearest_park_distance\", \"nearest_park_latitude\", \"nearest_park_longtitude\"]\n",
    "train_data = pd.merge(train_data, park_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_result = find_closest_distance_haversine(test_data, park_data)\n",
    "park_result.columns = [\"index\", \"nearest_park_distance\", \"nearest_park_latitude\", \"nearest_park_longtitude\"]\n",
    "test_data = pd.merge(test_data, park_result, on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 병합한 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = merged_train.columns.drop(\"interest_rate\").tolist() # 병합 기준이 될 column 리스트\n",
    "train_data = pd.merge(merged_train, train_data, on=on, how=\"left\")\n",
    "# train_data = train_data.drop(columns=[\"index\"])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = merged_test.columns.drop(\"interest_rate\").tolist() # 병합 기준이 될 column 리스트\n",
    "test_data = pd.merge(merged_test, test_data, on=on, how=\"left\")\n",
    "# test_data = test_data.drop(columns=[\"index\"])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built_year > 2024 행 삭제\n",
    "print(\"before train :\", train_data.shape)\n",
    "train_data = train_data[train_data[\"built_year\"] < 2024]\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "print(\"after train :\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"built_year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엘보우 방법(Elbow Method)\n",
    "- 클러스터 수에 따른 WCSS(Within-Cluster Sum of Squares)를 계산하고, 그래프에서 급격한 변화가 있는 지점을 찾음\n",
    "- 이 지점이 적절한 클러스터 수\n",
    "- 여기서는 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = train_data[['latitude', 'longitude']]\n",
    "wcss = []\n",
    "for i in range(1, 20):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(coords)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 20), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow Method로 찾은 n_cluster 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans 학습 (train 데이터에서)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(train_data[['latitude', 'longitude']])\n",
    "\n",
    "# 학습된 모델 저장\n",
    "joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "\n",
    "# 학습된 모델로 train 데이터에 레이블 할당\n",
    "train_data['region'] = kmeans.predict(train_data[['latitude', 'longitude']])\n",
    "\n",
    "# 지역별 전세가 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='region', y='deposit', data=train_data)\n",
    "plt.title('Deposit Distribution by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Deposit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 KMeans 모델 불러와서 test 데이터에 레이블 할당\n",
    "kmeans = joblib.load('kmeans_model.pkl')\n",
    "\n",
    "# Test 데이터에 동일한 KMeans 모델 적용\n",
    "test_data['region'] = kmeans.predict(test_data[['latitude', 'longitude']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터별 색상 지정\n",
    "colors = {0: 'red', 1: 'blue', 2: 'green'}  # 3개의 클러스터에 각각 색상 지정\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 각 클러스터에 해당하는 점들을 색상별로 플롯\n",
    "for cluster, color in colors.items():\n",
    "    clustered_data = train_data[train_data['region'] == cluster]\n",
    "    plt.scatter(clustered_data['longitude'], clustered_data['latitude'], \n",
    "                c=color, label=f'Region {cluster}', alpha=0.5, s=10)\n",
    "\n",
    "# 제목 및 축 레이블 설정\n",
    "plt.title('KMeans Clustering of Regions (Based on Latitude and Longitude)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# 범례 추가\n",
    "plt.legend()\n",
    "\n",
    "# 시각화 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클러스터별 색상 지정\n",
    "colors = {0: 'red', 1: 'blue', 2: 'green'}  # 3개의 클러스터에 각각 색상 지정\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 각 클러스터에 해당하는 점들을 색상별로 플롯\n",
    "for cluster, color in colors.items():\n",
    "    clustered_data = test_data[test_data['region'] == cluster]\n",
    "    plt.scatter(clustered_data['longitude'], clustered_data['latitude'], \n",
    "                c=color, label=f'Region {cluster}', alpha=0.5, s=10)\n",
    "\n",
    "# 제목 및 축 레이블 설정\n",
    "plt.title('KMeans Clustering of Regions (Based on Latitude and Longitude)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# 범례 추가\n",
    "plt.legend()\n",
    "\n",
    "# 시각화 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"log_deposit\"] = np.log1p(train_data[\"deposit\"])\n",
    "train_data[\"log_area_m2\"] = np.log1p(train_data[\"area_m2\"])\n",
    "train_data[\"log_school_distance\"] = np.log1p(train_data[\"nearest_school_distance\"])\n",
    "train_data[\"log_park_distance\"] = np.log1p(train_data[\"nearest_park_distance\"])\n",
    "train_data[\"log_subway_distance\"] = np.log1p(train_data[\"nearest_subway_distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"log_area_m2\"] = np.log1p(test_data[\"area_m2\"])\n",
    "test_data[\"log_school_distance\"] = np.log1p(test_data[\"nearest_school_distance\"])\n",
    "test_data[\"log_park_distance\"] = np.log1p(test_data[\"nearest_park_distance\"])\n",
    "test_data[\"log_subway_distance\"] = np.log1p(test_data[\"nearest_subway_distance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 및 타겟 설정\n",
    "train_cols = [\n",
    "    \"deposit\",\n",
    "    \"log_deposit\",\n",
    "    \"log_area_m2\",\n",
    "    \"built_year\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"log_subway_distance\",\n",
    "    \"log_school_distance\",\n",
    "    \"log_park_distance\",\n",
    "    \"contract_year_month\",\n",
    "    \"contract_day\",\n",
    "    \"region\"\n",
    "]\n",
    "train_data = train_data[train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 및 타겟 설정\n",
    "test_cols = [\n",
    "    \"log_area_m2\",\n",
    "    \"built_year\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"log_subway_distance\",\n",
    "    \"log_school_distance\",\n",
    "    \"log_park_distance\",\n",
    "    \"contract_year_month\",\n",
    "    \"contract_day\",\n",
    "    \"region\"\n",
    "]\n",
    "test_data = test_data[test_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"deposit\", \"log_deposit\"], inplace=False)\n",
    "y = train_data[[\"deposit\", \"log_deposit\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\"n_estimators\": 288, \"learning_rate\": 0.11112043349923437, \"max_depth\": 10, \"subsample\": 0.7511206505586165}\n",
    "#이전 파라미터 {'n_estimators': 289, 'learning_rate': 0.18917689569941643, 'max_depth': 10, 'subsample': 0.815154297680078}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "mae = []\n",
    "for train_idx, valid_idx in kfold.split(X, train_data[\"deposit\"]):\n",
    "    X_train, y_train = X.loc[train_idx, :], y.loc[train_idx, \"log_deposit\"]\n",
    "    X_valid, y_valid = X.loc[valid_idx, :], y.loc[valid_idx, \"deposit\"]\n",
    "    best_model = xgb.XGBRegressor(**best_params, tree_method=\"gpu_hist\", gpu_id=0, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_valid)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    mae.append(mean_absolute_error(y_valid, y_pred))\n",
    "\n",
    "print(f\"{np.mean(mae):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_log = best_model.predict(test_data)\n",
    "y_test = np.expm1(y_test_log) # 지수변환 (로그변환의 역변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지수변환 전/후 예측값 히스토그램 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.histplot(y_test_log, ax=axes[0])\n",
    "sns.histplot(y_test, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"deposit\"] = y_test\n",
    "sample_submission.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
